# parallel-saddle-point-714
Repository of a parallel saddle point optimizer project


Core Links:
- [Demystifying Parallel and Distributed Deep Learning: An In-Depth Concurrency Analysis](https://arxiv.org/pdf/1802.09941.pdf)
- [Stabilizing Adversarial Nets with Prediction Methods](https://openreview.net/pdf?id=Skj8Kag0Z)
- [StableGAN](https://github.com/shahsohil/stableGAN)


- Not as useful as I thought: [Training Neural Networks Without Gradients: A Scalable ADMM Approach](https://arxiv.org/pdf/1605.02026.pdf)

GANs:
- [Improved Techniques for Training GANs](https://arxiv.org/pdf/1606.03498.pdf)
- ["Awesome" Examples of GANS](https://github.com/nashory/gans-awesome-applications)

Distributed GANs (Why aren't there more of these?):
- [Training Generative Adversarial Models over Distributed Computing Systems](https://www.youtube.com/watch?v=joxS5NKXtdA)

Distribution idea Links:
- [Efficient Distributed SGD with Variance Reduction](https://arxiv.org/pdf/1512.02970.pdf)
- [What does fault tolerant Deep Learning need from MPI?](https://arxiv.org/pdf/1709.03316.pdf)
- [Training Inception in a Distributed Setting](https://github.com/tensorflow/models/tree/master/research/inception#how-to-train-from-scratch-in-a-distributed-setting)
